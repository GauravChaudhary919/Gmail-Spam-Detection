{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gmail Spam Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUcsee95Jzyn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6tmlt0_KHnx"
      },
      "source": [
        "import chardet\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjgh6K3UKZtm"
      },
      "source": [
        "dt = pd.read_csv(\"spam.csv\" , encoding = 'Windows-1252')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WJoFtcEKeCT"
      },
      "source": [
        "dt['spam'] = dt['type'].map({'spam' : 1 , 'ham' : 0}).astype(int)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnZrJYZyKj3i",
        "outputId": "c7b49a8a-7fe1-4121-e437-1527f5f7deea"
      },
      "source": [
        "print(\"columns in the given data:\")\n",
        "for col in dt.columns:\n",
        "  print(col)\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns in the given data:\n",
            "type\n",
            "text\n",
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VSJ5GJ1KnKS",
        "outputId": "7c2822e7-0992-4a9c-ea1e-19dee2cc6177"
      },
      "source": [
        "t=len(dt['type'])\n",
        "print(\"no of rows in given column:\",t)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of rows in given column: 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19zM-sewKqdK",
        "outputId": "e5a9a580-8852-49ca-d3f9-0262732ae49b"
      },
      "source": [
        "t=len(dt['text'])\n",
        "print(\"no of rows in liked column:\",t)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of rows in liked column: 116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axiG-r0zKwEo"
      },
      "source": [
        "dt['text'][4]\n",
        "def tokenizer(text):\n",
        "  return text.split()\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N77WX8LK3tN",
        "outputId": "df2818f9-433b-42e1-f966-4d1e8f841c07"
      },
      "source": [
        "dt['text'] = dt['text'].apply(tokenizer)\n",
        "dt['text'][4]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nah',\n",
              " 'I',\n",
              " \"don't\",\n",
              " 'think',\n",
              " 'he',\n",
              " 'goes',\n",
              " 'to',\n",
              " 'usf,',\n",
              " 'he',\n",
              " 'lives',\n",
              " 'around',\n",
              " 'here',\n",
              " 'though']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9SpfVySLHJ-"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "porter = SnowballStemmer(\"english\", ignore_stopwords = False )\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYbp_WvCLMa_",
        "outputId": "55c00759-b6d7-4095-9ff8-cae75fed50f0"
      },
      "source": [
        "def stem_it(text):\n",
        "  return[porter.stem(word) for word in text]\n",
        "dt['text'] = dt['text'].apply(stem_it)\n",
        "dt['text'][4]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nah',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'think',\n",
              " 'he',\n",
              " 'goe',\n",
              " 'to',\n",
              " 'usf,',\n",
              " 'he',\n",
              " 'live',\n",
              " 'around',\n",
              " 'here',\n",
              " 'though']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScwxAzj2LQxC"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm5O-6FOLaZK"
      },
      "source": [
        "def lemmit_it(text):\n",
        "  return [lemmatizer.lemmatize(word , pos = 'a') for word in text]\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4bNH3V5LdEF"
      },
      "source": [
        "dt['text'] = dt['text'].apply(lemmit_it)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrirJLA-LhRZ"
      },
      "source": [
        "import nltk\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrWhkys2LyrG",
        "outputId": "3b452ed8-6f76-48b4-f32a-5df09803f53e"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5HitTHGMAoG",
        "outputId": "ff68e983-1a5e-4a87-ff23-94a115784a6d"
      },
      "source": [
        "dt['text'][4]\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nah',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'think',\n",
              " 'he',\n",
              " 'goe',\n",
              " 'to',\n",
              " 'usf,',\n",
              " 'he',\n",
              " 'live',\n",
              " 'around',\n",
              " 'here',\n",
              " 'though']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3FLdetqMG6i"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"english\")\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXi4V5wPMJyn",
        "outputId": "65237a5c-a6b9-4a74-8cab-2bdd7630af9a"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU2gcB3DMODV"
      },
      "source": [
        "def stop_it(text):\n",
        "  review = [word for word in text if not word in stop_words]\n",
        "  return review"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU1VYineMUUe"
      },
      "source": [
        "dt['text'] = dt['text'].apply(stop_it)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFEwozRzMW_2",
        "outputId": "850cb7ab-bfb4-42ba-db51-8fb94777100d"
      },
      "source": [
        "dt['text'][4]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nah', 'think', 'goe', 'usf,', 'live', 'around', 'though']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "of4N6w_sMZOE",
        "outputId": "d28c0a09-5104-418e-dc6e-ec6cd19d83d4"
      },
      "source": [
        "dt.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text  spam\n",
              "0   ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
              "1   ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
              "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
              "3   ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
              "4   ham      [nah, think, goe, usf,, live, around, though]     0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9RtlnzMbx4"
      },
      "source": [
        "dt['text'] = dt['text'].apply(' '.join)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8rYZ856MfNa"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer()\n",
        "y=dt.spam.values\n",
        "x=tfidf.fit_transform(dt['text'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b334dghDMjxe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_text,y_train,y_text=train_test_split(x,y,random_state=1,test_size=0.2,shuffle=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BerI_uBFMmVV"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_text)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ukHMGeMoj1",
        "outputId": "6e33f44d-8b1d-4bba-8e6d-ff8ae7db067c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc_log = accuracy_score(y_pred, y_text)*100\n",
        "print(\"accuracy\",acc_log )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 87.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBc1LMg6MrD_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}